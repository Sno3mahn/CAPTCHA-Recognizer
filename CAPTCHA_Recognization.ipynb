{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CAPTCHA Recognization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOOuS/nq8Hj/HghWZIlsj3s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sno3mahn/CAPTCHA-Recognizer/blob/master/CAPTCHA_Recognization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb0eoyzbAr6X"
      },
      "source": [
        "# Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaCzghPYTEw5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras as k\n",
        "from keras.utils import np_utils\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import img_to_array, ImageDataGenerator\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, MaxPooling2D, Flatten, Conv2D, Dropout, Dense"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-kBn0GZA43m"
      },
      "source": [
        "# Loading Dataset and Preprocessing\n",
        "\n",
        "[Image Thresholding](https://docs.opencv.org/3.4/d7/d4d/tutorial_py_thresholding.html)\n",
        "\n",
        "[Closing, Dilation](https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html)\n",
        "\n",
        "[Gaussian Blur](https://docs.opencv.org/3.4/d4/d13/tutorial_py_filtering.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2m3v52LTZPA"
      },
      "source": [
        "X=[]\n",
        "y=[]\n",
        "\n",
        "# Since there are subfolders inside the input directory, we've used nested loops\n",
        "for dirname, _, filenames in os.walk('.'):\n",
        "    for filename in filenames:\n",
        "        path=os.path.join(dirname, filename) \n",
        "        \n",
        "# Preprocessing the image:\n",
        "# - read image\n",
        "        image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# - Adaptive Threshold: For every pixel, the same threshold value is applied. If the pixel value\n",
        "# is smaller than the threshold, it is set to 0, otherwise it is set to a maximum value\n",
        "# It removes the greyish tinge off the image.\n",
        "        image = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 145, 0)\n",
        "  \n",
        "# - Closing: It is useful in closing small holes inside the foreground objects, \n",
        "# or small black points on the object\n",
        "        kernel = np.ones((5,5),np.uint8)\n",
        "        image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
        "        \n",
        "# - Dilation: So it increases the white region in the image or \n",
        "# size of foreground object increases\n",
        "        kernel = np.ones((2,2),np.uint8)\n",
        "        image = cv2.dilate(image, kernel, iterations = 1)\n",
        " \n",
        "# - Blur: As in one-dimensional signals, images also can be filtered with various low-pass filters (LPF), high-pass filters (HPF), etc.\n",
        "# LPF helps in removing noise, blurring images, etc. HPF filters help in finding edges in images.\n",
        "        image = cv2.GaussianBlur(image, (5,5), 0)\n",
        " \n",
        "\n",
        "# Splitting up the image into sections of each character\n",
        "        x=[image[10:50,30:50],image[10:50,50:70],\n",
        "                 image[10:50,70:90],image[10:50,90:110],image[10:50,110:130]]\n",
        "\n",
        "# Labelling segments with the image name\n",
        "        for i in range(5):\n",
        "            X.append(img_to_array(Image.fromarray(x[i])))\n",
        "            y.append(path[len(path)-9:len(path)-4][i])\n",
        "X=np.array(X)\n",
        "y=np.array(y)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNrdadTBBFqP"
      },
      "source": [
        "# Scaling X values; Label Encoding and One Hot Encoding the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj9OUXtWTaze"
      },
      "source": [
        "X=X.astype('float32')\n",
        "X/=255\n",
        "\n",
        "y_le = LabelEncoder().fit_transform(y)\n",
        "y_ohe = OneHotEncoder(sparse = False).fit_transform(y_le.reshape(len(y_le),1))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_ohe, test_size = 0.2, random_state = 42)\n",
        "\n",
        "row, col = X.shape[1],X.shape[2]\n",
        "categories = y_ohe.shape[1]\n",
        "\n",
        "info = {y_le[i] : y[i] for i in range(len(y))}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYPtZPenBL62"
      },
      "source": [
        "# Creating the CNN architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwjsdN9LBPSi"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=16,kernel_size=(3,3), padding='same', input_shape=(row,col,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=16,kernel_size=(3,3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=32,kernel_size=(3,3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=32,kernel_size=(3,3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1500))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(categories))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = 'adam' ,\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65sVKuJfBTW0"
      },
      "source": [
        "# Fitting and training data into model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVODWojcBUbr"
      },
      "source": [
        "batch_size = 150\n",
        "epochs = 200\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(X_test, y_test),\n",
        "          shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asDtgPqhBXut"
      },
      "source": [
        "# Evaluating performance of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xITer2VBYaO"
      },
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqYL-NifBazL"
      },
      "source": [
        "# Prediction Function:\n",
        "\n",
        "**The purpose of this function is to process raw images into model-comprehensible data for better prediction. As we've done in data preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBUrn3osBdFL"
      },
      "source": [
        "def pred (img_path) :\n",
        "    \n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    \n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    \n",
        "    image = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 145, 0)\n",
        "    image = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 145, 0)\n",
        "    kernel = np.ones((5,5),np.uint8)\n",
        "    image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
        "    kernel = np.ones((2,2),np.uint8)\n",
        "    image = cv2.dilate(image, kernel, iterations = 1)\n",
        "    image = cv2.GaussianBlur(image, (5,5), 0)\n",
        "    \n",
        "    \n",
        "    x = [image[10:50, 30:50], image[10:50, 50:70], image[10:50, 70:90],\n",
        "                  image[10:50, 90:110], image[10:50, 110:130]]\n",
        "    \n",
        "    X_pred = []\n",
        "    for i in range(5) :\n",
        "        X_pred.append(img_to_array(Image.fromarray(x[i])))\n",
        "    \n",
        "    X_pred = np.array(X_pred)\n",
        "    X_pred/= 255.0\n",
        "    \n",
        "    y_pred = model.predict(X_pred)\n",
        "    y_pred = np.argmax(y_pred, axis = 1)\n",
        "    \n",
        "    print('Prediction: ', end='')\n",
        "    for res in y_pred :\n",
        "        print(info[res], end='')\n",
        "        \n",
        "    print('\\nActual:    ', img_path[len(img_path)-9:len(img_path)-4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5ebe92fBk0j"
      },
      "source": [
        "pred('samples/245y5.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-ZHxji1BnMB"
      },
      "source": [
        "model.save('captcha_recognizer.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}